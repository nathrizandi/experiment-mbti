{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ru-nvKU9Nu6I"
      },
      "source": [
        "**TFIDF+W2V✅ | AUGMENT✅**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELhR7RtAFvtS"
      },
      "source": [
        "#Import Library + Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e4mQxiPDzs8",
        "outputId": "d8225bea-ec6b-4941-a08b-8824658fa343"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_xhS5uskGDGO",
        "outputId": "6f7d46b1-c5fc-407c-d335-205a8b27cd2d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/TI14_Personal/mbti_1.csv\n"
          ]
        }
      ],
      "source": [
        "# List files in the directory to verify existence\n",
        "!ls /content/drive/MyDrive/TI14_Personal/mbti_1.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkpN1G3FCBL-",
        "outputId": "d19116f8-5300-4a59-c9d4-62971c31f7b2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/TI14_Personal/augmented_train_set1.csv\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/TI14_Personal/augmented_train_set1.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93gsi01YbpLd",
        "outputId": "8d352cd0-1c41-44b8-833d-721bed16f7f2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/TI14_Personal/test_set.csv\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/TI14_Personal/test_set.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HW26SxC8GKyV",
        "outputId": "9bfe36db-730f-492d-aa52-931fd09d5ba7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import xgboost as xgb\n",
        "from sklearn.svm import SVC\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from gensim.models import Word2Vec\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords, wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.util import ngrams\n",
        "from gensim.models import KeyedVectors\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint as sp_randint\n",
        "from scipy.stats import uniform\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import nltk\n",
        "import re\n",
        "import os\n",
        "import random\n",
        "from collections import Counter\n",
        "from google.colab import files\n",
        "from nltk import pos_tag, ne_chunk\n",
        "from nltk.util import ngrams\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gWwpHA2YGQXV"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/TI14_Personal/mbti_1.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "id": "qYFIDZAIGYVu",
        "outputId": "93f2398e-def2-40dd-d49c-9951a92ddc52"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>type</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>posts</th>\n",
              "      <td>object</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ],
            "text/plain": [
              "type     object\n",
              "posts    object\n",
              "dtype: object"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPNIbu6_GdDU"
      },
      "source": [
        "#Data Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_f4XAcUUmY19"
      },
      "outputs": [],
      "source": [
        "# Function to remove MBTI type words from the posts\n",
        "def remove_mbti_words(text):\n",
        "    mbti_types = ['INFJ', 'INTJ', 'ENFJ', 'ENTJ', 'INFP', 'INTP', 'ENFP', 'ENTP',\n",
        "                  'ISFJ', 'ISTJ', 'ESFJ', 'ESTJ', 'ISFP', 'ISTP', 'ESFP', 'ESTP']\n",
        "    for mbti in mbti_types:\n",
        "        text = re.sub(mbti, '', text, flags=re.IGNORECASE)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5WRMCUXmZfN"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    text = remove_mbti_words(text)  # Remove MBTI words first\n",
        "    # Lowercase\n",
        "    text = text.lower()\n",
        "    # Remove URLs\n",
        "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
        "    # Replace underscores with space\n",
        "    text = re.sub(r'_', ' ', text)\n",
        "    # Replace punctuation with a space\n",
        "    text = re.sub(r'[^\\w\\s]', ' ', text)\n",
        "    # Remove numbers\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "    # Remove extra spaces\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    # Tokenize\n",
        "    tokens = word_tokenize(text)\n",
        "    # Remove stopwords\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    tokens = [word for word in tokens if word not in stop_words]\n",
        "    # Lemmatization\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
        "    return ' '.join(tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMAKLxI_gt4l"
      },
      "outputs": [],
      "source": [
        "# Apply preprocessing\n",
        "df['posts_cleaned'] = df['posts'].apply(preprocess_text)  # Apply the preprocessing to each post"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJZGjV17wwD7"
      },
      "outputs": [],
      "source": [
        "# Add MBTI dimension columns\n",
        "df['I/E'] = df['type'].apply(lambda x: x[0])\n",
        "df['N/S'] = df['type'].apply(lambda x: x[1])\n",
        "df['F/T'] = df['type'].apply(lambda x: x[2])\n",
        "df['J/P'] = df['type'].apply(lambda x: x[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lw36db3iwyuD"
      },
      "outputs": [],
      "source": [
        "# Save the cleaned posts\n",
        "df['tokens'] = df['posts_cleaned'].apply(word_tokenize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UIpMWhgYHN2a",
        "outputId": "d924cd04-c1a8-4ca8-f63f-6b86f43f7b10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original vs Cleaned Data Sample:\n",
            "                                               posts  \\\n",
            "0  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...   \n",
            "1  'I'm finding the lack of me in these posts ver...   \n",
            "2  'Good one  _____   https://www.youtube.com/wat...   \n",
            "3  'Dear INTP,   I enjoyed our conversation the o...   \n",
            "4  'You're fired.|||That's another silly misconce...   \n",
            "\n",
            "                                       posts_cleaned  \n",
            "0  moment sportscenter top ten play prank life ch...  \n",
            "1  finding lack post alarming sex boring position...  \n",
            "2  good one course say know blessing curse absolu...  \n",
            "3  dear enjoyed conversation day esoteric gabbing...  \n",
            "4  fired another silly misconception approaching ...  \n"
          ]
        }
      ],
      "source": [
        "# Verify the cleaned posts\n",
        "print(\"Original vs Cleaned Data Sample:\")\n",
        "print(df[['posts', 'posts_cleaned']].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "dfHAj8ZkxCsZ",
        "outputId": "b5194bc8-f11e-4a0a-a7aa-2c9a56c578c1"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 8675,\n  \"fields\": [\n    {\n      \"column\": \"type\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"INFJ\",\n          \"ENTP\",\n          \"ENFJ\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"posts\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 8675,\n        \"samples\": [\n          \"'This. When I lie it's to avoid an unreasonable response for something I did that was completely justifiable to me but if I was to try to justify to someone else they'd be too hung up on what I did. I...|||Your IQ (SD15): 128|||I typically have very difficult times maintaining friends I've come to realize. I've had people I talk to for years and I still don't want to talk to them... I DID, but then I just got bored of them,...|||An INTJ friend of mine told me she really hates eating because it's so repetitive. As an INTP I don't really feel bothered, I don't really register eating I just do it while I'm thinking about...|||Similar Minds Advanced Test|||INTP 9 sx/so I have a lot of friends but I only have one I speak about how I actually feel with and only 1 other that I talk about what I am actually thinking about - with regards to...|||Getting close to someone and end up wanting to be infinitely close to them and end up merging every damn time.|||Interesting topic, I know two ENFP's, 1 is strange, as an INTP I view some of the stuff she does as 'coming onto me'?  - sort of. She gets really close and is very open to me, just what ENFP's do,...|||As far as I'm aware this is normal in all people, it's not so much your pessimistic self but just that humans are social creatures and you will feel better after socializing for that reason. Being...|||Vajrayaksa  How dare you use Lelouch as an INTP! He is an INTJ I say!|||I normally think about doing this stuff but don't actually do it.|||You'll probably find that commenting on their nihilistic thoughts logically would make them more open. Dismissing ideas will merely make them agree with that idea more as they'll feel a need to...|||Don't worry, calling me thinker is the same.|||INTJ - Winter - Coldest ENTJ - Summer - Actually doing things ENTP - Spring - Bringing out the fun in people INTP - Autumn - No one ever notices this season|||I've known a couple ENTP's, one ENTJ and an INTJ and it kind of went ENTP>ENTJ>ENTP>INTJ I love being able to constantly talk with ENTP's but also they need to know when to stop talking, if an ENTP...|||If you mean actually 1v1ing yourself I also have done this, maybe I'm wrong but I find it pretty easy to think about the most logical move the player I am playing should make with the information...|||Gender: female Age: 19-29 Intelligence: gifted Idea adoption: early-adopter MBTI personality profile: ESFP Closest alternative we found: ESFJ  I think I killed it when it told me to write...|||I'm fine with them, I'm more on shortage of people I'd ever want to do them with but that's on the grounds that any socialising that could be done could just as well be done over skype without the...|||I used to use pencils then I was told that my teachers wanted me to use pens only - so I used pens only. I haven't used a pencil - excluding my games of naughts and crosses earlier - in a couple...|||I'd love to own either a calm house out somewhere distant with a porch and a log cabin aesthetic - fuck it, I want a log cabin. OR I'd actually really like the idea of being in one of those smokey...|||Yeah I enjoy listening to lyrics but it doesn't make much of a difference if they're present or not, if they are there they're just another part of the instrumental I don't necessarily listen to...|||More often then not someone is only going to be fully entering my world if they invite me into theirs first and it's similar or we're friends on the internet - because then there are few...|||What did you get me today?  My head = Shit, shit, shit what did I miss, is it your birthday? Was I supposed to get you something? Are we that good friends that I should be buying you stuff? I...|||I frequently say it as an off hand thing, someone does something really awesome and I say fuck yeah I love you man or something like that. If I was to say it in a genuine way then it'd feel really...|||So something strange has been happening recently, my interest was drawn to naughts and crosses and how I could make it more enjoyable to play. I started by increasing the grid size and tried...|||You could tell them your thoughts. You could not tell them your thoughts and continue to brew over it. I think that there's no reason to be ashamed or annoyed about anything and if you don't...|||loudly, whilst he drew his|||and the baby platypi quivered|||particularly in the higher regions|||Starting with a lingering feeling|||What's the point of stopping? Why does it matter what they're called? Guilty pleasures are pleasures for a reason, does it matter that much?|||their own god dam story|||post multiple times to do|||It's impressive how people would|||Maximum of five words per line, feel free to say other stuff in the most but make sure it's clear which is the five words.     Once upon a time in|||someone who appreciates c.c. Fuck yeah!|||Yeezus can't we come to a reasonable conclusion without you picking a fight? It's not being open minded.|||More often then not I judge them purely by how they judge me, I have a dark sense of humor that I'm not exactly secretive about, I get along with most people on the grounds that I'm just friendly to...|||I chose my avatar as it's an awesome art work of Kaneki from Tokyo Ghoul and by god I loved the manga, love tragedies. Name is a slightly altered version of my name, George - Georgius. Liked the Halo...|||Violence in this situation would probably be a faster way to get things done for both parties involved and especially on the receiving end, trying to talk sense into someone who just said something...|||But surely the point that everyone would be worse off initially isn't relevant? Rebuilding a system would obviously have it's issues here and there.  I'm not crying revolution and I'm not being...|||We'd call it Diagon Alley!|||I'm with you, I make a pretty big point of not being a person for people to expect feelings from, I want to be that person but I just feel wrong, someones crying their eyes out and here I am lying...|||Good call but that's just how I read it ^^'|||What about a four dimensional plane.|||Why airplane why not aeroplane?|||Hit them for having the expectation that you should live up to their expectations which is infuriating in and of itself probably.|||It's just because hitting a women is politically incorrect and some women will use that to their advantage.|||What he's saying is that they should assume that if they say something worthy of being hit for, that they should be grateful when they're not hit for it, not expect not to be hit just on the basis...|||Is it particularly common amongst INTP's and other types to just acknowledge another sides point of view even though socially you shouldn't. What I mean by this is I can't have conversation with...'\",\n          \"'I said zero flexibility and little time for dating. Going around sifting through dates to find one that clicks isn't going to be as viable.  That has nothing to do with maintaining a relationship I...|||How you've come to the conclusion I have nothing to offer  merely because I am busy is beyond me.       No not really. Again, more made up stuff.|||okay, this isn't cool.  you're specifically looking to get into a relationship because you're about to enter a life phase where you will not have any resources to give to a relationship?   that is...|||I do take it slow (that's why I'm still single), but I'm not interested in making friends. I  have friends. Enough for my liking. I'm interested in going on dates with the intent of entering a...|||Absolutely not for me. I find the idea repugnant, actually.|||People could have been polite. Maybe average is a more conservative bet. And I'm not claiming I'm a social butterfly. I'm just a normal guy who is introverted but not a social doofus.  I don't...|||I'm probably giving up the online thing here when my next subscription runs out. After that I really don't know where to look. Bars are a definite no. I don't understand where people meet their...|||I've tried both ways, actually. The last few women I have gone out with have gotten really weird and/or ignored my backhanded compliments. I don't know what to do anymore. Seems I get screwed either...|||I'm actually pretty healthy.     Sorry you feel that way. Not sure which ones you met, but assholes exist everywhere. The number isn't anywhere near 99% though.|||If anything I err on the side of being indifferent. Definitely not overeager.|||Yeah my close friends don't live near me anymore.  The issue is that I have been meeting people, a good amount, and nothing works. I want to know why it is that deformed, infirm, mentally unstable,...|||My friends are in worse positions than I am. Asking them isn't going to help.   As far as feedback, not really because that seems like an extraordinarily awkward thing to ask someone you barely...|||So, I'm a 26 year old male who has been striking out time and time again when it comes to relationships. I've been in one relationship my entire life that lasted like 1.5 years and ended when I was...|||I don't think this sort of dating method is very reasonable, and at best, it is counterproductive. Being friends first just throws a wrench in what is normally a smooth dating process. When you fear...|||Never was a kiss.|||I appreciate the feedback. I think I'm just going to tell her we shouldn't hang out unless she can dedicate a decent amount of time to it. What is happening right now is dragging things out and...|||I don't know. After thinking more, I'm on the verge of giving up. It has nothing to do with seeing her infrequently, or not making it official or what have you. It's that she keeps things...|||I don't know. I'm not a model or anything but I'm decent looking. She's drop dead gorgeous and nice and smart. Guys are always after her it seems. But I'm also smarter and have better career...|||I like your answer, but maybe I'm just being optimistic. It is basically, what I've been doing. I can't shake the feeling that she wouldn't be giving me any of her time if she weren't interested and...|||How am I supposed to know if an INFJ just wants to be friends? Things have been very weird with an INFJ I've been seeing. I've been very upfront about my intentions and she essentially told me she...|||Interesting. I find it unusual INFJs are known for taking forever to open up and trust people yet all the responses so far have indicated kissing in 3 or fewer dates....|||My INFJ friend has been with an INTJ, and i don't want to bust your confidence but even though she liked him at first, she soon found out that he was putting her down and felt caged. I can see that...|||Enlighten us infjs. Also indicate your gender and if you initiated.|||Well there was more than that. She also said she was basically trying to figure out if I'm trustworthy and decent.|||Those two things seem at odds. How can you be simultaneously not saying things that need to be said but also being proactively aggressive?|||Pretty much yeah. Women just do not enjoy my company on any level. I'm in the same situation. Never had any female friends, dated one person in my life and it lasted a little less than two years. The...|||I don't think that is going to help me dig myself out of the very clingy seeming hole I dug myself. I basically asked her if she knew I was romantically interested and she responded of course lol...|||I should have just let things proceed at a natural pace. Pretty pissed at myself. About zero chance she speaks to me again.|||I read through most of that thread. From what I can tell I never did anything egregious. Good chance she lost interest after my bluntness though lol.|||I broke that off shortly after my post. I felt like a slime ball. I only did it because people were telling me she's a lost cause and I should see other people. BTW I have a very well developed...|||Update on this. Told her I liked her and got no reassurance she liked me or even that she wasn't interested. Those who said she was ambivalent were right. I'm pretty much calling it off at this point...|||Yeah so I told her and didn't get an affirmation she liked me nor that she didn't. She basically said she had known for a while I like her. Pretty much what I expected. Probably going to call it...|||Is the crystal ball reference supposed to mean your guess is as good as mine or what? Edit: guess not :p|||So I've gone on six or so dates with an INFJ over a 3 month period (she's pretty busy, and me too) and recently I feel like progress has been a little glacial. For a bit I thought she was warming up...|||She hates texting.  And yeah, she told me how picky she was about people recently and that normally she wouldn't give anyone the time of day.|||You would literally have to have an autism spectrum disorder. I would know.  Not to mention you don't tell someone who is just friends how much you like them. That would be more than bizarre.|||It's kind of hard to get to the point of officially dating when you have no idea what is going on in her head. For all I know an attempt to kiss her would result in abject horror and assault...|||Spoke to her last night, she essentially said she likes me a lot and would normally never make any time for people unless she was obligated to. But she also indirectly used the word friend but it...|||So I met an INFJ female a while back, and we've been out like five or so times on a date. They go well, we get along, everything seems nice. I find her very attractive and we have quite a bit in...|||'  I don't know, I kind of have a rule that I don't compliment a female on her appearance until she trusts me. I did compliment her personality a few times.  She is extremely cautious from what I...|||Well, now I have a new question. Went on a second date a few days ago and it went well and she said she wanted to meet up again. The problem is, there hasn't been an ounce of flirting or touching...|||She started initiating with me and asked if I'm free soon. -_-    If there is anything to be learned it is don't play the analysis game. You will lose.|||Expectations of....?|||I don't know. I can't really fault a strong introvert for being wary about someone she doesn't really know. Number 2 is cruel, but it is how modern dating works.    Pretty sure this isn't the...|||I don't know. I can't really fault a strong introvert for being wary about someone she doesn't really know. Number 2 is cruel, but it is how modern dating works.    Pretty sure this isn't the...|||Thanks, option 1 seems most likely. It seems whenever I finally get her to open up there is like a cascade of good conversation that finally ensues, but it is like pulling teeth initially. Then I...|||I'm socially retarded and would know that if a random stranger asked for my contact info then asked me out for drinks or lunch then the person probably isn't interested in just being friends.|||So I shouldn't be deterred by the fact she doesn't really ever reach out to me? I don't enjoy appearing like someone who can't take a hint or who puts someone else in an awkward situation. I worry...|||No this seems to fit her pretty well.|||Thanks for the advice everyone. I appreciate your taking the time to respond.'\",\n          \"'This has to be written with bias or something, I'm not sure how you could even say that truthfully. For some reason you put subjectivity for both God and man? It says nothing.    That makes no...|||??? How?  The main priority of the church is written throughout it's texts for the past nearly 2000 years and reverberated throughout the church's dialogues both before and after the incident about...|||That's an annoying phrasing, as it's just obtuse and confusing to newcomers. I don't blame you for your response there.    Why must the revealed knowledge not speak truth but contain a bias...|||There are no priestly desk jobs. The closest thing you have to being a priest that gets you away from people is being a monk and that in itself is very different.  I am telling you they did it out...|||No, you really won't. You can't just go to an INTP and assume their intelligence level. That would end in failure. Don't be afraid to ask big questions when musing with the INTP and just try to...|||Heresy is, like, the core reason most all Christian in-fighting occurs. Everything else is minor disputes about theological opinions.|||That's exceedingly subjective. See what they're interested in, strike up a conversation about it. Definitely ask them their thoughts.|||To dismiss my concept of it is to dismiss all history on the topic, dismiss what the apostles taught, and literally all sects of Christianity. But fine, whatever.|||Do cool shit, discuss ideas, have patience, don't try to judge personally too quickly or control them. ALSO, make the first move to show you're interested in talking with them.|||I used to feel about the same until I read the book Self-Made Man, where a lesbian 'butch' woman dressed like a man and tried to live as one. She noticed herself being considered a feminine man quite...|||I'm not sure what the hell is going on in this thread but I would like to say I know no ENTJs personally, I don't think. It'd be neat, though.|||All churches are forms of political institutions. Catholic and Orthodox ones have the benefit of being centralized. All sects have declared doctrine in one way or another.  You're speaking against...|||And here is the most boring post in the whole thread.|||What part? If it's the idea of a teaching authority, you have a problem with all church until the 13th century. If it's the idea of a group being guided by the Holy Spirit in their decisions on...|||For Catholics, the church has a dual meaning. The whole of the believers (the Body of Christ) and the political institution. For Catholicism, their teachings of Christ are said to be protected by...|||Priests were relocated to other parishes so they may quiet down the criticism of the time and handle thing themselves. Again, poor decision but that was their decision.  The church's first priority...|||Well sure then. Yes, the church did protect child offenders. The church's reasoning was the image of the church itself and the their leadership's own ignorance of the size of the problem. The church...|||Edit: Based double post|||No, it really isn't. The Bible itself is the canon collection of texts. The Bible was established once the theological and historical work was done to establish the canon and it was not modified...|||Yes, nevermind it because the two claims do not contradict each other at all. I could work through how there is no contradiction if you're struggling.    I wouldn't say all, no. That's a...|||? There's no way to tell? But many of them depend on logic and/or history that contradicts or ruins their claims? Granted there are a few cases of we're yet to be able to know but many of it can...|||The problem of induction is a grand way of humbling yourself about scientific findings when you're younger. It brings into question if what we know is what we could call true.|||Rubix cubes.|||Pantheism makes no sense. I'd advise otherwise. Atheism and Abrahamic Theism are the only two rational choices.|||You, motherfucker.|||What is the meaning of everything? The universe exists. We are to learn to love in it.|||Disappointed 24 year old reporting in.  Good luck, OP.|||This is exceedingly naive. The early church, before scripture, applied their teaching to better society. After scripture, it was held in high esteem as a basis to properly better society. Most work...|||From the Catholic Catechism (list of official teaching) here is how we are to read the Bible:  III. THE HOLY SPIRIT, INTERPRETER OF SCRIPTURE   109 In Sacred Scripture, God speaks to man in a...|||I never liked people pointing to the Scandinavian model for the success of their economic system and not their incredible oil and natural resource supply compared to their small populations.|||While shit just got stupid for a moment. Lets try to get back on track.|||You're pretty smart, you know that?  Look at this fucker, she thinks I'm smart. Pfft.|||Exceedingly poor.|||I've just been told I'm bright, but I'm sure most everyone else says the same to the kids.|||And what of you?|||The most efficient way to remove self-doubt is to stop doubting yourself so much. Faith and trust, nigga.|||You suspect wrongly. I like the chatter and I'm being friendly with you. I seriously do hope you have a good day too.|||Indeed you do. Feel free to ask/argue/chat/or bullshit with me if you want. Have a good one, man.|||I'd say that's a stretch to say. Catholics believe the bible was inspired by God but written by men. Orthodox do too. As they assembled the biblical canon I'd have to say they have the greatest say...|||Edit: Welp.|||I see the arguments for inconsistencies. Sometimes they aren't actually inconsistencies. Sometimes they are. I find the simplest example of a true one being the rabbit that is apparently chewing...|||Sorry to take so long to get back to you, my internet has been screwing up horribly.  As for the answer, there was a considerable amount of things that got me off the atheist train but if I were to...|||The believing portion was a long and arduous process for me. I researched culture as a hobby and eventually I rolled around to religion. It was an interesting topic for me and I eventually began to...|||To your first statement... just... what. Where did that even come from? Of course they can know love, though with God they can know it fully, I'd argue.  As for Hell, it's taken a variety of...|||I'm very mixed on him. His criticism of Christianity (and envy, now that I've seen the video) is, while popular, piss poor and Max Scheler did a wonderful job making an argument otherwise on his...|||People believing in something as incontrovertibly true is what gets people into a murderous rage? Why just the incontrovertibly true? Why not the empirically true? Why not just majority opinion? To...|||Sure thing. Sounds sorta similar to the Epicurean Paradox.  Suffering/free will exists to strengthen the good. If you create a people so they may know love they cannot sincerely know love if they...|||Yo. Christian INTP here.  Anything you want?|||It's not we can make healthy children! it's we only let the healthy babies live! which is the issue. It's a moral issue about the innate value of life.|||249210'\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"I/E\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"E\",\n          \"I\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"N/S\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"S\",\n          \"N\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"F/T\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"T\",\n          \"F\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"J/P\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"P\",\n          \"J\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-41b85016-a6af-4c6a-a2d2-4f0657919eb1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type</th>\n",
              "      <th>posts</th>\n",
              "      <th>I/E</th>\n",
              "      <th>N/S</th>\n",
              "      <th>F/T</th>\n",
              "      <th>J/P</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>INFJ</td>\n",
              "      <td>'http://www.youtube.com/watch?v=qsXHcwe3krw|||...</td>\n",
              "      <td>I</td>\n",
              "      <td>N</td>\n",
              "      <td>F</td>\n",
              "      <td>J</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ENTP</td>\n",
              "      <td>'I'm finding the lack of me in these posts ver...</td>\n",
              "      <td>E</td>\n",
              "      <td>N</td>\n",
              "      <td>T</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>INTP</td>\n",
              "      <td>'Good one  _____   https://www.youtube.com/wat...</td>\n",
              "      <td>I</td>\n",
              "      <td>N</td>\n",
              "      <td>T</td>\n",
              "      <td>P</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>INTJ</td>\n",
              "      <td>'Dear INTP,   I enjoyed our conversation the o...</td>\n",
              "      <td>I</td>\n",
              "      <td>N</td>\n",
              "      <td>T</td>\n",
              "      <td>J</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ENTJ</td>\n",
              "      <td>'You're fired.|||That's another silly misconce...</td>\n",
              "      <td>E</td>\n",
              "      <td>N</td>\n",
              "      <td>T</td>\n",
              "      <td>J</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-41b85016-a6af-4c6a-a2d2-4f0657919eb1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-41b85016-a6af-4c6a-a2d2-4f0657919eb1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-41b85016-a6af-4c6a-a2d2-4f0657919eb1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-15ebea51-3f34-4251-9635-0f8ef7732d2c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-15ebea51-3f34-4251-9635-0f8ef7732d2c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-15ebea51-3f34-4251-9635-0f8ef7732d2c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "   type                                              posts I/E N/S F/T J/P\n",
              "0  INFJ  'http://www.youtube.com/watch?v=qsXHcwe3krw|||...   I   N   F   J\n",
              "1  ENTP  'I'm finding the lack of me in these posts ver...   E   N   T   P\n",
              "2  INTP  'Good one  _____   https://www.youtube.com/wat...   I   N   T   P\n",
              "3  INTJ  'Dear INTP,   I enjoyed our conversation the o...   I   N   T   J\n",
              "4  ENTJ  'You're fired.|||That's another silly misconce...   E   N   T   J"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "dSeoAduFsn-T",
        "outputId": "a6ea2390-aadb-462e-8624-b9acf78664c5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>F/T</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>F</th>\n",
              "      <td>4694</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T</th>\n",
              "      <td>3981</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "F/T\n",
              "F    4694\n",
              "T    3981\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['F/T'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "SFKqkFuHHWvW",
        "outputId": "6e0a9e41-0530-4036-e30c-55c7f70fd22a"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_38dee46c-a1e3-4c33-aae4-4e2cd91a6c07\", \"preprocessed_mbti1.csv\", 146550549)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Save the DataFrame to a CSV file locally\n",
        "csv_filename = 'preprocessed_mbti1.csv'\n",
        "df.to_csv(csv_filename, index=False)\n",
        "\n",
        "# Download the file to your local machine\n",
        "files.download(csv_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 321
        },
        "id": "c4H_rQ-yHjst",
        "outputId": "c9d1829b-3b76-48fa-a880-68d087f1d7d8"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'preprocessed_mbti1.csv'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-481f96e30a31>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load the CSV file into a new DataFrame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'preprocessed_mbti1.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    946\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 948\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    949\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1446\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1447\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1448\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1703\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1704\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1705\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1706\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1707\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    861\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    864\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'preprocessed_mbti1.csv'"
          ]
        }
      ],
      "source": [
        "# Load the CSV file into a new DataFrame\n",
        "df = pd.read_csv('preprocessed_mbti1.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AC2BC6DtHp2D"
      },
      "source": [
        "#Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKvoBjE0kkBL",
        "outputId": "55365480-883a-472c-ee33-9d206d6a3340"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Distribution before splitting:\n",
            "type\n",
            "INFP    0.211182\n",
            "INFJ    0.169452\n",
            "INTP    0.150317\n",
            "INTJ    0.125764\n",
            "ENTP    0.078963\n",
            "ENFP    0.077810\n",
            "ISTP    0.038847\n",
            "ISFP    0.031239\n",
            "ENTJ    0.026628\n",
            "ISTJ    0.023631\n",
            "ENFJ    0.021902\n",
            "ISFJ    0.019135\n",
            "ESTP    0.010259\n",
            "ESFP    0.005533\n",
            "ESFJ    0.004841\n",
            "ESTJ    0.004496\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Check distribution before splitting\n",
        "print(\"Distribution before splitting:\")\n",
        "print(df['type'].value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M7Ikht5MHtt1"
      },
      "outputs": [],
      "source": [
        "# Split data into training and testing sets (80% train, 20% test)\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['type'], random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzT_ub2VkpxX",
        "outputId": "80825fce-4635-486f-9022-7eab7ca742ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Distribution in training set:\n",
            "type\n",
            "INFP    0.211239\n",
            "INFJ    0.169452\n",
            "INTP    0.150288\n",
            "INTJ    0.125793\n",
            "ENTP    0.078963\n",
            "ENFP    0.077810\n",
            "ISTP    0.038905\n",
            "ISFP    0.031268\n",
            "ENTJ    0.026657\n",
            "ISTJ    0.023631\n",
            "ENFJ    0.021902\n",
            "ISFJ    0.019164\n",
            "ESTP    0.010231\n",
            "ESFP    0.005476\n",
            "ESFJ    0.004755\n",
            "ESTJ    0.004467\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Distribution in test set:\n",
            "type\n",
            "INFP    0.210951\n",
            "INFJ    0.169452\n",
            "INTP    0.150432\n",
            "INTJ    0.125648\n",
            "ENTP    0.078963\n",
            "ENFP    0.077810\n",
            "ISTP    0.038617\n",
            "ISFP    0.031124\n",
            "ENTJ    0.026513\n",
            "ISTJ    0.023631\n",
            "ENFJ    0.021902\n",
            "ISFJ    0.019020\n",
            "ESTP    0.010375\n",
            "ESFP    0.005764\n",
            "ESFJ    0.005187\n",
            "ESTJ    0.004611\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "# Check distribution after splitting\n",
        "print(\"\\nDistribution in training set:\")\n",
        "print(train_df['type'].value_counts(normalize=True))\n",
        "\n",
        "print(\"\\nDistribution in test set:\")\n",
        "print(test_df['type'].value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ja9qgqpHy4jO"
      },
      "outputs": [],
      "source": [
        "# Save train and test sets to CSV\n",
        "train_df.to_csv('train_set.csv', index=False)\n",
        "test_df.to_csv('test_set.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "RXURhqBeycDE",
        "outputId": "d602e3f9-b40c-4f6a-8944-b920dc9b60db"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_480a01b8-99f8-47c1-9bf6-d37a29ab6613\", \"test_set.csv\", 29294933)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Download the file to your local machine\n",
        "files.download('test_set.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yvUMj5J7ybX_"
      },
      "outputs": [],
      "source": [
        "# Load the CSV file into a new DataFrame\n",
        "train_df = pd.read_csv('train_set.csv')\n",
        "test_df = pd.read_csv('test_set.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bwdiyw9QOPFX"
      },
      "source": [
        "#Data Augmentation for Training Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwL_5TmpR4TV"
      },
      "outputs": [],
      "source": [
        "def get_synonyms(word):\n",
        "    synonyms = set()\n",
        "    for syn in wordnet.synsets(word):\n",
        "        for lemma in syn.lemmas():\n",
        "            synonyms.add(lemma.name())\n",
        "    if word in synonyms:\n",
        "        synonyms.remove(word)\n",
        "    return list(synonyms)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oosSVpWOrGCD"
      },
      "outputs": [],
      "source": [
        "def random_insertion(text, n=1):\n",
        "    words = text.split()\n",
        "    if len(words) == 0:\n",
        "        return text\n",
        "    for _ in range(n):\n",
        "        new_word = random.choice(words)\n",
        "        synonyms = get_synonyms(new_word)\n",
        "        if synonyms:\n",
        "            synonym = random.choice(synonyms)\n",
        "            insert_position = random.randint(0, len(words))\n",
        "            words.insert(insert_position, synonym)\n",
        "    return ' '.join(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XizhCwOxrKv3"
      },
      "outputs": [],
      "source": [
        "def random_synonym_replacement(text):\n",
        "    words = text.split()\n",
        "    if len(words) == 0:\n",
        "        return text\n",
        "    random_word = random.choice(words)\n",
        "    synonyms = get_synonyms(random_word)\n",
        "    if synonyms:\n",
        "        synonym = random.choice(synonyms)\n",
        "        new_words = [synonym if word == random_word else word for word in words]\n",
        "        return ' '.join(new_words)\n",
        "    else:\n",
        "        return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QHYSX1P6rL0P"
      },
      "outputs": [],
      "source": [
        "def random_deletion(text, p=0.1):\n",
        "    words = text.split()\n",
        "    if len(words) == 0:\n",
        "        return text\n",
        "    if len(words) == 1:\n",
        "        return text\n",
        "    new_words = [word for word in words if random.uniform(0, 1) > p]\n",
        "    return ' '.join(new_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPr-xid_rRmR"
      },
      "outputs": [],
      "source": [
        "def random_swap(text, n=1):\n",
        "    words = text.split()\n",
        "    if len(words) < 2:\n",
        "        return text\n",
        "    for _ in range(n):\n",
        "        idx1, idx2 = random.sample(range(len(words)), 2)\n",
        "        words[idx1], words[idx2] = words[idx2], words[idx1]\n",
        "    return ' '.join(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3LWazYhhzpfm"
      },
      "outputs": [],
      "source": [
        "# Convert all entries in the 'posts_cleaned' column to strings, replacing NaNs with empty strings\n",
        "train_df['posts_cleaned'] = train_df['posts_cleaned'].astype(str).fillna('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFztEI92rYlO"
      },
      "outputs": [],
      "source": [
        "# Augmentation process\n",
        "total_target_samples = 25000\n",
        "current_total_samples = len(train_df)\n",
        "class_counts = train_df['type'].value_counts()\n",
        "\n",
        "current_proportions = class_counts / current_total_samples\n",
        "target_class_counts = (current_proportions * total_target_samples).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "8zSdV8jNrcT_",
        "outputId": "40b54fa0-febc-47c8-a18b-8fe5aa53b78d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>type</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>INFP</th>\n",
              "      <td>5280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>INFJ</th>\n",
              "      <td>4236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>INTP</th>\n",
              "      <td>3757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>INTJ</th>\n",
              "      <td>3144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ENTP</th>\n",
              "      <td>1974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ENFP</th>\n",
              "      <td>1945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ISTP</th>\n",
              "      <td>972</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ISFP</th>\n",
              "      <td>781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ENTJ</th>\n",
              "      <td>666</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ISTJ</th>\n",
              "      <td>590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ENFJ</th>\n",
              "      <td>547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ISFJ</th>\n",
              "      <td>479</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ESTP</th>\n",
              "      <td>255</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ESFP</th>\n",
              "      <td>136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ESFJ</th>\n",
              "      <td>118</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ESTJ</th>\n",
              "      <td>111</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ],
            "text/plain": [
              "type\n",
              "INFP    5280\n",
              "INFJ    4236\n",
              "INTP    3757\n",
              "INTJ    3144\n",
              "ENTP    1974\n",
              "ENFP    1945\n",
              "ISTP     972\n",
              "ISFP     781\n",
              "ENTJ     666\n",
              "ISTJ     590\n",
              "ENFJ     547\n",
              "ISFJ     479\n",
              "ESTP     255\n",
              "ESFP     136\n",
              "ESFJ     118\n",
              "ESTJ     111\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "target_class_counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YNhmSstre9a"
      },
      "outputs": [],
      "source": [
        "augmented_texts = []\n",
        "augmented_labels = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Im2dpDHJrhIh"
      },
      "outputs": [],
      "source": [
        "for label in class_counts.index:\n",
        "    current_size = class_counts[label]\n",
        "    target_size = target_class_counts[label]\n",
        "    texts_to_augment = train_df[train_df['type'] == label]['posts_cleaned']\n",
        "    num_samples_needed = target_size - current_size\n",
        "\n",
        "    while num_samples_needed > 0:\n",
        "        for text in texts_to_augment:\n",
        "            if num_samples_needed <= 0:\n",
        "                break\n",
        "            augmented_text = random.choice([\n",
        "                random_deletion(text),\n",
        "                random_swap(text),\n",
        "                random_insertion(text),\n",
        "                random_synonym_replacement(text)\n",
        "            ])\n",
        "            augmented_texts.append(augmented_text)\n",
        "            augmented_labels.append(label)\n",
        "            num_samples_needed -= 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZg3z-yUl95m"
      },
      "outputs": [],
      "source": [
        "# Append the augmented data to the original training set\n",
        "augmented_df = pd.DataFrame({\n",
        "    'posts_cleaned': augmented_texts,\n",
        "    'type': augmented_labels\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwoidcFcz2Fe"
      },
      "outputs": [],
      "source": [
        "train_df = pd.concat([train_df, augmented_df])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IJ4VO17OmA4S",
        "outputId": "0898a584-7ff2-4ed1-f5d2-b99fadf0d2fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "type\n",
            "INFP    0.211276\n",
            "INFJ    0.169501\n",
            "INTP    0.150334\n",
            "INTJ    0.125805\n",
            "ENTP    0.078988\n",
            "ENFP    0.077828\n",
            "ISTP    0.038894\n",
            "ISFP    0.031251\n",
            "ENTJ    0.026650\n",
            "ISTJ    0.023608\n",
            "ENFJ    0.021888\n",
            "ISFJ    0.019167\n",
            "ESTP    0.010204\n",
            "ESFP    0.005442\n",
            "ESFJ    0.004722\n",
            "ESTJ    0.004442\n",
            "Name: proportion, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "print(train_df['type'].value_counts(normalize=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BT4lVhBKvTet"
      },
      "outputs": [],
      "source": [
        "train_df.to_csv('augmented_train_set1.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "R-VShxPzvhR6",
        "outputId": "0dd15edf-016e-459c-a743-da4f131526c3"
      },
      "outputs": [
        {
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/javascript": [
              "download(\"download_fd3d0213-dd9d-4355-9ee5-7aaa1bf31cea\", \"augmented_train_set1.csv\", 186749070)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "files.download('augmented_train_set1.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GujEAOsV0Od7"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('/content/drive/MyDrive/TI14_Personal/augmented_train_set1.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8TjH2i75sJU"
      },
      "outputs": [],
      "source": [
        "test_df = pd.read_csv('/content/drive/MyDrive/TI14_Personal/test_set.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v05JjkuySeZC"
      },
      "source": [
        "#Feature Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tKocqN_0rSK"
      },
      "outputs": [],
      "source": [
        "# Convert all entries in the 'posts_cleaned' column to strings, replacing NaNs with empty strings\n",
        "train_df['posts_cleaned'] = train_df['posts_cleaned'].astype(str).fillna('')\n",
        "test_df['posts_cleaned'] = test_df['posts_cleaned'].astype(str).fillna('')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eiXF5vP9nhNG"
      },
      "outputs": [],
      "source": [
        "# Tokenize the data\n",
        "train_tokens = train_df['posts_cleaned'].apply(word_tokenize)\n",
        "test_tokens = test_df['posts_cleaned'].apply(word_tokenize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PyNQoYrGwNcQ"
      },
      "outputs": [],
      "source": [
        "# Train Word2Vec model\n",
        "word2vec_model = Word2Vec(sentences=train_tokens, vector_size=400, window=5, min_count=1, workers=4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MmAJYEN1pIQZ"
      },
      "outputs": [],
      "source": [
        "# Function to get Word2Vec features\n",
        "def get_word2vec_features(text, model, num_features):\n",
        "    words = text.split()\n",
        "    feature_vector = np.zeros((num_features,), dtype=\"float32\")\n",
        "    for word in words:\n",
        "        if word in model.wv:\n",
        "            feature_vector = np.add(feature_vector, model.wv[word])\n",
        "    if len(words) > 0:\n",
        "        feature_vector = np.divide(feature_vector, len(words))\n",
        "    return feature_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oFaVBE9P3-wj"
      },
      "outputs": [],
      "source": [
        "# Extract Word2Vec features\n",
        "train_word2vec_features = np.array([get_word2vec_features(text, word2vec_model, 400) for text in train_df['posts_cleaned']])\n",
        "test_word2vec_features = np.array([get_word2vec_features(text, word2vec_model, 400) for text in test_df['posts_cleaned']])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6psDX4Vrh21y"
      },
      "outputs": [],
      "source": [
        "# TF-IDF vectorization\n",
        "tfidf_vectorizer = TfidfVectorizer(max_features=400)\n",
        "train_tfidf_features = tfidf_vectorizer.fit_transform(train_df['posts_cleaned']).toarray()\n",
        "test_tfidf_features = tfidf_vectorizer.transform(test_df['posts_cleaned']).toarray()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kPEoUMVLSfpp"
      },
      "outputs": [],
      "source": [
        "# Combine Word2Vec and TF-IDF features\n",
        "train_combined_features = np.hstack((train_word2vec_features, train_tfidf_features))\n",
        "test_combined_features = np.hstack((test_word2vec_features, test_tfidf_features))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAvuONewUBIr"
      },
      "source": [
        "#Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLxRVJuK3JQi"
      },
      "outputs": [],
      "source": [
        "# Define a mapping from MBTI type to dimensions\n",
        "def get_mbti_dimensions(mbti_type):\n",
        "    ie = 1 if mbti_type[0] == 'I' else 0\n",
        "    ns = 1 if mbti_type[1] == 'N' else 0\n",
        "    ft = 1 if mbti_type[2] == 'F' else 0\n",
        "    jp = 1 if mbti_type[3] == 'J' else 0\n",
        "    return ie, ns, ft, jp\n",
        "\n",
        "# Apply the function to both train and test sets\n",
        "train_df[['I/E', 'N/S', 'F/T', 'J/P']] = train_df['type'].apply(lambda x: pd.Series(get_mbti_dimensions(x)))\n",
        "test_df[['I/E', 'N/S', 'F/T', 'J/P']] = test_df['type'].apply(lambda x: pd.Series(get_mbti_dimensions(x)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Y0yFBtVp9rt"
      },
      "outputs": [],
      "source": [
        "# Define the RandomForest model\n",
        "rf_model = RandomForestClassifier(random_state=42, max_depth=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "ybl7hYd-2HSI",
        "outputId": "7549aad1-db5e-4193-d99c-eaf3df624c84"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(max_depth=10, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(max_depth=10, random_state=42)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomForestClassifier(max_depth=10, random_state=42)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model on class type\n",
        "rf_model.fit(train_combined_features, train_df['type'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5t3daezk2J4b"
      },
      "outputs": [],
      "source": [
        "# Predict on the train set and map to dimensions\n",
        "train_predictions = rf_model.predict(train_combined_features)\n",
        "train_pred_dimensions = pd.DataFrame([get_mbti_dimensions(pred) for pred in train_predictions], columns=['I/E', 'N/S', 'F/T', 'J/P'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SXdTJ-m62Qr4"
      },
      "outputs": [],
      "source": [
        "# Predict on the test set and map to dimensions\n",
        "test_predictions = rf_model.predict(test_combined_features)\n",
        "test_pred_dimensions = pd.DataFrame([get_mbti_dimensions(pred) for pred in test_predictions], columns=['I/E', 'N/S', 'F/T', 'J/P'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UEw2w8RX2TRh",
        "outputId": "f34ba393-ef34-4082-cc9c-5f0e57ad8976"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy for I/E: 0.9262934656476332\n",
            "Test Accuracy for I/E: 0.7659942363112392\n",
            "Average Accuracy for I/E: 0.8461438509794361\n",
            "Precision for I/E: 0.7697674418604651\n",
            "Recall for I/E: 0.992503748125937\n",
            "F1-Score for I/E: 0.8670595939751146\n",
            "\n",
            "Train Accuracy for N/S: 0.9221719819134888\n",
            "Test Accuracy for N/S: 0.861671469740634\n",
            "Average Accuracy for N/S: 0.8919217258270614\n",
            "Precision for N/S: 0.861671469740634\n",
            "Recall for N/S: 1.0\n",
            "F1-Score for N/S: 0.9256965944272446\n",
            "\n",
            "Train Accuracy for F/T: 0.9428994437997679\n",
            "Test Accuracy for F/T: 0.7089337175792507\n",
            "Average Accuracy for F/T: 0.8259165806895092\n",
            "Precision for F/T: 0.683277027027027\n",
            "Recall for F/T: 0.8615548455804047\n",
            "F1-Score for F/T: 0.7621290626471974\n",
            "\n",
            "Train Accuracy for J/P: 0.9360969949181706\n",
            "Test Accuracy for J/P: 0.6230547550432277\n",
            "Average Accuracy for J/P: 0.7795758749806991\n",
            "Precision for J/P: 0.534020618556701\n",
            "Recall for J/P: 0.37700145560407566\n",
            "F1-Score for J/P: 0.44197952218430037\n",
            "\n",
            "Overall Average Accuracy: 0.8358895081191764\n",
            "Overall Precision: 0.7121841392962067\n",
            "Overall Recall: 0.8077650123276043\n",
            "Overall F1-Score: 0.7492161933084642\n"
          ]
        }
      ],
      "source": [
        "# Initialize lists to store metrics for each dimension\n",
        "average_accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "# Calculate metrics for each dimension and their averages\n",
        "for dimension in ['I/E', 'N/S', 'F/T', 'J/P']:\n",
        "    train_accuracy = accuracy_score(train_df[dimension], train_pred_dimensions[dimension])\n",
        "    test_accuracy = accuracy_score(test_df[dimension], test_pred_dimensions[dimension])\n",
        "\n",
        "    # Calculate the average accuracy for this dimension\n",
        "    average_accuracy = (train_accuracy + test_accuracy) / 2\n",
        "    average_accuracies.append(average_accuracy)\n",
        "\n",
        "    # Calculate precision, recall, and f1-score for the test set\n",
        "    precision = precision_score(test_df[dimension], test_pred_dimensions[dimension])\n",
        "    recall = recall_score(test_df[dimension], test_pred_dimensions[dimension])\n",
        "    f1 = f1_score(test_df[dimension], test_pred_dimensions[dimension])\n",
        "\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    print(f\"Train Accuracy for {dimension}: {train_accuracy}\")\n",
        "    print(f\"Test Accuracy for {dimension}: {test_accuracy}\")\n",
        "    print(f\"Average Accuracy for {dimension}: {average_accuracy}\")\n",
        "    print(f\"Precision for {dimension}: {precision}\")\n",
        "    print(f\"Recall for {dimension}: {recall}\")\n",
        "    print(f\"F1-Score for {dimension}: {f1}\\n\")\n",
        "\n",
        "# If you want to calculate an overall average accuracy, precision, recall, and f1-score across all dimensions\n",
        "overall_average_accuracy = sum(average_accuracies) / len(average_accuracies)\n",
        "overall_precision = sum(precisions) / len(precisions)\n",
        "overall_recall = sum(recalls) / len(recalls)\n",
        "overall_f1_score = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "print(f\"Overall Average Accuracy: {overall_average_accuracy}\")\n",
        "print(f\"Overall Precision: {overall_precision}\")\n",
        "print(f\"Overall Recall: {overall_recall}\")\n",
        "print(f\"Overall F1-Score: {overall_f1_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7kjAw7wA-7nK"
      },
      "outputs": [],
      "source": [
        "# Define the SVM model\n",
        "svm_model = SVC(random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "ppgxOqXCd89Q",
        "outputId": "9e9309da-c2fd-467b-aed3-f472b5df8e9c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(random_state=42)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "SVC(random_state=42)"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model on class type\n",
        "svm_model.fit(train_combined_features, train_df['type'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ow7OhM6m--r8"
      },
      "outputs": [],
      "source": [
        "# Predict on the train set and map to dimensions\n",
        "train_predictions = svm_model.predict(train_combined_features)\n",
        "train_pred_dimensions = pd.DataFrame([get_mbti_dimensions(pred) for pred in train_predictions], columns=['I/E', 'N/S', 'F/T', 'J/P'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FR6wdFFs_AjZ"
      },
      "outputs": [],
      "source": [
        "# Predict on the test set and map to dimensions\n",
        "test_predictions = svm_model.predict(test_combined_features)\n",
        "test_pred_dimensions = pd.DataFrame([get_mbti_dimensions(pred) for pred in test_predictions], columns=['I/E', 'N/S', 'F/T', 'J/P'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shDlX7MgAK0q",
        "outputId": "722f6933-41aa-41ba-b772-9f32e47e591e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy for I/E: 0.8311392101156416\n",
            "Test Accuracy for I/E: 0.7746397694524496\n",
            "Average Accuracy for I/E: 0.8028894897840456\n",
            "Precision for I/E: 0.8075668623613829\n",
            "Recall for I/E: 0.9280359820089955\n",
            "F1-Score for I/E: 0.8636205092431113\n",
            "\n",
            "Train Accuracy for N/S: 0.8829978792365252\n",
            "Test Accuracy for N/S: 0.8680115273775216\n",
            "Average Accuracy for N/S: 0.8755047033070233\n",
            "Precision for N/S: 0.8710433763188745\n",
            "Recall for N/S: 0.9939799331103679\n",
            "F1-Score for N/S: 0.9284598562949077\n",
            "\n",
            "Train Accuracy for F/T: 0.8401424512824617\n",
            "Test Accuracy for F/T: 0.7648414985590778\n",
            "Average Accuracy for F/T: 0.8024919749207697\n",
            "Precision for F/T: 0.7565217391304347\n",
            "Recall for F/T: 0.8338658146964856\n",
            "F1-Score for F/T: 0.7933130699088146\n",
            "\n",
            "Train Accuracy for J/P: 0.7631147212996678\n",
            "Test Accuracy for J/P: 0.6570605187319885\n",
            "Average Accuracy for J/P: 0.7100876200158281\n",
            "Precision for J/P: 0.5793103448275863\n",
            "Recall for J/P: 0.4890829694323144\n",
            "F1-Score for J/P: 0.5303867403314917\n",
            "\n",
            "Overall Average Accuracy: 0.7977434470069167\n",
            "Overall Precision: 0.7536105806595697\n",
            "Overall Recall: 0.8112411748120408\n",
            "Overall F1-Score: 0.7789450439445813\n"
          ]
        }
      ],
      "source": [
        "# Initialize lists to store metrics for each dimension\n",
        "average_accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "# Calculate metrics for each dimension and their averages\n",
        "for dimension in ['I/E', 'N/S', 'F/T', 'J/P']:\n",
        "    train_accuracy = accuracy_score(train_df[dimension], train_pred_dimensions[dimension])\n",
        "    test_accuracy = accuracy_score(test_df[dimension], test_pred_dimensions[dimension])\n",
        "\n",
        "    # Calculate the average accuracy for this dimension\n",
        "    average_accuracy = (train_accuracy + test_accuracy) / 2\n",
        "    average_accuracies.append(average_accuracy)\n",
        "\n",
        "    # Calculate precision, recall, and f1-score for the test set\n",
        "    precision = precision_score(test_df[dimension], test_pred_dimensions[dimension])\n",
        "    recall = recall_score(test_df[dimension], test_pred_dimensions[dimension])\n",
        "    f1 = f1_score(test_df[dimension], test_pred_dimensions[dimension])\n",
        "\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    print(f\"Train Accuracy for {dimension}: {train_accuracy}\")\n",
        "    print(f\"Test Accuracy for {dimension}: {test_accuracy}\")\n",
        "    print(f\"Average Accuracy for {dimension}: {average_accuracy}\")\n",
        "    print(f\"Precision for {dimension}: {precision}\")\n",
        "    print(f\"Recall for {dimension}: {recall}\")\n",
        "    print(f\"F1-Score for {dimension}: {f1}\\n\")\n",
        "\n",
        "# If you want to calculate an overall average accuracy, precision, recall, and f1-score across all dimensions\n",
        "overall_average_accuracy = sum(average_accuracies) / len(average_accuracies)\n",
        "overall_precision = sum(precisions) / len(precisions)\n",
        "overall_recall = sum(recalls) / len(recalls)\n",
        "overall_f1_score = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "print(f\"Overall Average Accuracy: {overall_average_accuracy}\")\n",
        "print(f\"Overall Precision: {overall_precision}\")\n",
        "print(f\"Overall Recall: {overall_recall}\")\n",
        "print(f\"Overall F1-Score: {overall_f1_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JA7ZANGkEK6V"
      },
      "outputs": [],
      "source": [
        "# Define the LightGBM model\n",
        "lgbm_model = LGBMClassifier(random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        },
        "id": "BLwLwKjAEhOZ",
        "outputId": "b2c23f52-bc29-47a0-9161-1838b467f707"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.282899 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 204000\n",
            "[LightGBM] [Info] Number of data points in the train set: 24991, number of used features: 800\n",
            "[LightGBM] [Info] Start training from score -3.821822\n",
            "[LightGBM] [Info] Start training from score -2.553254\n",
            "[LightGBM] [Info] Start training from score -3.624981\n",
            "[LightGBM] [Info] Start training from score -2.538454\n",
            "[LightGBM] [Info] Start training from score -5.355586\n",
            "[LightGBM] [Info] Start training from score -5.213616\n",
            "[LightGBM] [Info] Start training from score -5.416741\n",
            "[LightGBM] [Info] Start training from score -4.585007\n",
            "[LightGBM] [Info] Start training from score -1.774896\n",
            "[LightGBM] [Info] Start training from score -1.554590\n",
            "[LightGBM] [Info] Start training from score -2.073020\n",
            "[LightGBM] [Info] Start training from score -1.894895\n",
            "[LightGBM] [Info] Start training from score -3.954570\n",
            "[LightGBM] [Info] Start training from score -3.465696\n",
            "[LightGBM] [Info] Start training from score -3.746149\n",
            "[LightGBM] [Info] Start training from score -3.246915\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LGBMClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LGBMClassifier</label><div class=\"sk-toggleable__content\"><pre>LGBMClassifier(random_state=42)</pre></div></div></div></div></div>"
            ],
            "text/plain": [
              "LGBMClassifier(random_state=42)"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model on class type\n",
        "lgbm_model.fit(train_combined_features, train_df['type'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3O-FHwEaEkMH"
      },
      "outputs": [],
      "source": [
        "# Predict on the train set and map to dimensions\n",
        "train_predictions = lgbm_model.predict(train_combined_features)\n",
        "train_pred_dimensions = pd.DataFrame([get_mbti_dimensions(pred) for pred in train_predictions], columns=['I/E', 'N/S', 'F/T', 'J/P'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jx4eH8y4EmcA"
      },
      "outputs": [],
      "source": [
        "# Predict on the test set and map to dimensions\n",
        "test_predictions = lgbm_model.predict(test_combined_features)\n",
        "test_pred_dimensions = pd.DataFrame([get_mbti_dimensions(pred) for pred in test_predictions], columns=['I/E', 'N/S', 'F/T', 'J/P'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0xO_25KEoQx",
        "outputId": "89c642ab-08d8-47ed-9101-d489a8502398"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Accuracy for I/E: 1.0\n",
            "Test Accuracy for I/E: 0.7717579250720461\n",
            "Average Accuracy for I/E: 0.885878962536023\n",
            "Precision for I/E: 0.7945979899497487\n",
            "Recall for I/E: 0.9482758620689655\n",
            "F1-Score for I/E: 0.8646616541353384\n",
            "\n",
            "Train Accuracy for N/S: 1.0\n",
            "Test Accuracy for N/S: 0.8622478386167147\n",
            "Average Accuracy for N/S: 0.9311239193083574\n",
            "Precision for N/S: 0.8651162790697674\n",
            "Recall for N/S: 0.9953177257525083\n",
            "F1-Score for N/S: 0.9256609642301711\n",
            "\n",
            "Train Accuracy for F/T: 1.0\n",
            "Test Accuracy for F/T: 0.7400576368876081\n",
            "Average Accuracy for F/T: 0.8700288184438041\n",
            "Precision for F/T: 0.7293233082706767\n",
            "Recall for F/T: 0.8264110756123536\n",
            "F1-Score for F/T: 0.7748377433849226\n",
            "\n",
            "Train Accuracy for J/P: 1.0\n",
            "Test Accuracy for J/P: 0.6443804034582132\n",
            "Average Accuracy for J/P: 0.8221902017291066\n",
            "Precision for J/P: 0.5583333333333333\n",
            "Recall for J/P: 0.487627365356623\n",
            "F1-Score for J/P: 0.5205905205905206\n",
            "\n",
            "Overall Average Accuracy: 0.8773054755043228\n",
            "Overall Precision: 0.7368427276558815\n",
            "Overall Recall: 0.8144080071976126\n",
            "Overall F1-Score: 0.7714377205852381\n"
          ]
        }
      ],
      "source": [
        "# Initialize lists to store metrics for each dimension\n",
        "average_accuracies = []\n",
        "precisions = []\n",
        "recalls = []\n",
        "f1_scores = []\n",
        "\n",
        "# Calculate metrics for each dimension and their averages\n",
        "for dimension in ['I/E', 'N/S', 'F/T', 'J/P']:\n",
        "    train_accuracy = accuracy_score(train_df[dimension], train_pred_dimensions[dimension])\n",
        "    test_accuracy = accuracy_score(test_df[dimension], test_pred_dimensions[dimension])\n",
        "\n",
        "    # Calculate the average accuracy for this dimension\n",
        "    average_accuracy = (train_accuracy + test_accuracy) / 2\n",
        "    average_accuracies.append(average_accuracy)\n",
        "\n",
        "    # Calculate precision, recall, and f1-score for the test set\n",
        "    precision = precision_score(test_df[dimension], test_pred_dimensions[dimension])\n",
        "    recall = recall_score(test_df[dimension], test_pred_dimensions[dimension])\n",
        "    f1 = f1_score(test_df[dimension], test_pred_dimensions[dimension])\n",
        "\n",
        "    precisions.append(precision)\n",
        "    recalls.append(recall)\n",
        "    f1_scores.append(f1)\n",
        "\n",
        "    print(f\"Train Accuracy for {dimension}: {train_accuracy}\")\n",
        "    print(f\"Test Accuracy for {dimension}: {test_accuracy}\")\n",
        "    print(f\"Average Accuracy for {dimension}: {average_accuracy}\")\n",
        "    print(f\"Precision for {dimension}: {precision}\")\n",
        "    print(f\"Recall for {dimension}: {recall}\")\n",
        "    print(f\"F1-Score for {dimension}: {f1}\\n\")\n",
        "\n",
        "# If you want to calculate an overall average accuracy, precision, recall, and f1-score across all dimensions\n",
        "overall_average_accuracy = sum(average_accuracies) / len(average_accuracies)\n",
        "overall_precision = sum(precisions) / len(precisions)\n",
        "overall_recall = sum(recalls) / len(recalls)\n",
        "overall_f1_score = sum(f1_scores) / len(f1_scores)\n",
        "\n",
        "print(f\"Overall Average Accuracy: {overall_average_accuracy}\")\n",
        "print(f\"Overall Precision: {overall_precision}\")\n",
        "print(f\"Overall Recall: {overall_recall}\")\n",
        "print(f\"Overall F1-Score: {overall_f1_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anwvM-SiJou1"
      },
      "source": [
        "#*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YIojvlEAJqfG"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q4c0IRfjJts8"
      },
      "outputs": [],
      "source": [
        "# Define the adjusted parameter grid for RandomForest\n",
        "param_dist_rf = {\n",
        "    'n_estimators': randint(50, 150),  # Fewer trees\n",
        "    'max_depth': [3, 5, 7, 10],  # Further restrict depth\n",
        "    'min_samples_split': randint(5, 15),  # Increase min_samples_split\n",
        "    'min_samples_leaf': randint(2, 5),  # Increase min_samples_leaf\n",
        "    'max_features': ['auto', 'sqrt'],  # Limit the number of features\n",
        "    'bootstrap': [True, False]\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R18mNg-zJv_P"
      },
      "outputs": [],
      "source": [
        "# Create a RandomForest model\n",
        "rf_model = RandomForestClassifier(random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ooJCeEXJyq8"
      },
      "outputs": [],
      "source": [
        "# Randomized search on hyperparameters\n",
        "rf_random_search = RandomizedSearchCV(estimator=rf_model, param_distributions=param_dist_rf,\n",
        "                                      n_iter=15, cv=4, verbose=1, random_state=42, n_jobs=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 796
        },
        "id": "Wi8Ylyoo-k1j",
        "outputId": "5e2c3e8f-a971-4a76-abd0-ac9c831ef3f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 4 folds for each of 15 candidates, totalling 60 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
            "32 fits failed out of a total of 60.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "25 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1145, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 638, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'sqrt', 'log2'} or None. Got 'auto' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "7 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 1145, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/base.py\", line 638, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/sklearn/utils/_param_validation.py\", line 96, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'max_features' parameter of RandomForestClassifier must be an int in the range [1, inf), a float in the range (0.0, 1.0], a str among {'log2', 'sqrt'} or None. Got 'auto' instead.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan 0.4760512         nan 0.80625005        nan        nan\n",
            "        nan        nan        nan 0.7387456  0.28098111        nan\n",
            " 0.81393279 0.83045879 0.34352364]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomizedSearchCV(cv=4, estimator=RandomForestClassifier(random_state=42),\n",
              "                   n_iter=15, n_jobs=-1,\n",
              "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
              "                                        &#x27;max_depth&#x27;: [3, 5, 7, 10],\n",
              "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
              "                                        &#x27;min_samples_leaf&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7d90e63e8af0&gt;,\n",
              "                                        &#x27;min_samples_split&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7d90e63ea5f0&gt;,\n",
              "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7d90e63e9630&gt;},\n",
              "                   random_state=42, verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" ><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomizedSearchCV</label><div class=\"sk-toggleable__content\"><pre>RandomizedSearchCV(cv=4, estimator=RandomForestClassifier(random_state=42),\n",
              "                   n_iter=15, n_jobs=-1,\n",
              "                   param_distributions={&#x27;bootstrap&#x27;: [True, False],\n",
              "                                        &#x27;max_depth&#x27;: [3, 5, 7, 10],\n",
              "                                        &#x27;max_features&#x27;: [&#x27;auto&#x27;, &#x27;sqrt&#x27;],\n",
              "                                        &#x27;min_samples_leaf&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7d90e63e8af0&gt;,\n",
              "                                        &#x27;min_samples_split&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7d90e63ea5f0&gt;,\n",
              "                                        &#x27;n_estimators&#x27;: &lt;scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7d90e63e9630&gt;},\n",
              "                   random_state=42, verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "RandomizedSearchCV(cv=4, estimator=RandomForestClassifier(random_state=42),\n",
              "                   n_iter=15, n_jobs=-1,\n",
              "                   param_distributions={'bootstrap': [True, False],\n",
              "                                        'max_depth': [3, 5, 7, 10],\n",
              "                                        'max_features': ['auto', 'sqrt'],\n",
              "                                        'min_samples_leaf': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7d90e63e8af0>,\n",
              "                                        'min_samples_split': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7d90e63ea5f0>,\n",
              "                                        'n_estimators': <scipy.stats._distn_infrastructure.rv_discrete_frozen object at 0x7d90e63e9630>},\n",
              "                   random_state=42, verbose=1)"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Fit the random search model\n",
        "rf_random_search.fit(train_combined_features, train_df['type'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZxEdWfC-mQu",
        "outputId": "3044eb55-ecee-4739-d230-4ad6551be12d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best RF Parameters: {'bootstrap': False, 'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 6, 'n_estimators': 139}\n"
          ]
        }
      ],
      "source": [
        "# Best hyperparameters\n",
        "print(\"Best RF Parameters:\", rf_random_search.best_params_)\n",
        "\n",
        "# Use the best model\n",
        "best_rf_model = rf_random_search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JdOTCJY3-9gg",
        "outputId": "54304b0b-9656-4f85-8437-77e811bc9390"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Forest Results:\n",
            "Train Accuracy for I/E: 0.9351366491937098\n",
            "Test Accuracy for I/E: 0.7706051873198847\n",
            "Average Accuracy for I/E: 0.8528709182567973\n",
            "\n",
            "Train Precision for I/E: 0.9224534816804143\n",
            "Test Precision for I/E: 0.7727272727272727\n",
            "Train Recall for I/E: 0.999792088985914\n",
            "Test Recall for I/E: 0.9940029985007496\n",
            "Train F1 Score for I/E: 0.9595669851088773\n",
            "Test F1 Score for I/E: 0.8695081967213115\n",
            "\n",
            "\n",
            "Train Accuracy for N/S: 0.9254131487335441\n",
            "Test Accuracy for N/S: 0.861671469740634\n",
            "Average Accuracy for N/S: 0.8935423092370891\n",
            "\n",
            "Train Precision for N/S: 0.9203861102806133\n",
            "Test Precision for N/S: 0.861671469740634\n",
            "Train Recall for N/S: 1.0\n",
            "Test Recall for N/S: 1.0\n",
            "Train F1 Score for N/S: 0.9585427694497576\n",
            "Test F1 Score for N/S: 0.9256965944272446\n",
            "\n",
            "\n",
            "Train Accuracy for F/T: 0.949781921491737\n",
            "Test Accuracy for F/T: 0.7129682997118155\n",
            "Average Accuracy for F/T: 0.8313751106017763\n",
            "\n",
            "Train Precision for F/T: 0.9324543467531552\n",
            "Test Precision for F/T: 0.6876595744680851\n",
            "Train Recall for F/T: 0.9780357935216684\n",
            "Test Recall for F/T: 0.8604898828541001\n",
            "Train F1 Score for F/T: 0.9547013174517235\n",
            "Test F1 Score for F/T: 0.7644276253547777\n",
            "\n",
            "\n",
            "Train Accuracy for J/P: 0.9411788243767757\n",
            "Test Accuracy for J/P: 0.6167146974063401\n",
            "Average Accuracy for J/P: 0.7789467608915579\n",
            "\n",
            "Train Precision for J/P: 0.967469745753303\n",
            "Test Precision for J/P: 0.5240174672489083\n",
            "Train Recall for J/P: 0.881002931958346\n",
            "Test Recall for J/P: 0.34934497816593885\n",
            "Train F1 Score for J/P: 0.9222139908985078\n",
            "Test F1 Score for J/P: 0.4192139737991266\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate on dimensions using the best_rf_model\n",
        "print(\"Random Forest Results:\")\n",
        "for dimension in ['I/E', 'N/S', 'F/T', 'J/P']:\n",
        "    # Train predictions\n",
        "    train_predictions = best_rf_model.predict(train_combined_features)\n",
        "    train_pred_dimensions = pd.DataFrame([get_mbti_dimensions(pred) for pred in train_predictions], columns=['I/E', 'N/S', 'F/T', 'J/P'])\n",
        "    train_accuracy = accuracy_score(train_df[dimension], train_pred_dimensions[dimension])\n",
        "    train_precision = precision_score(train_df[dimension], train_pred_dimensions[dimension])\n",
        "    train_recall = recall_score(train_df[dimension], train_pred_dimensions[dimension])\n",
        "    train_f1 = f1_score(train_df[dimension], train_pred_dimensions[dimension])\n",
        "\n",
        "    # Test predictions\n",
        "    test_predictions = best_rf_model.predict(test_combined_features)\n",
        "    test_pred_dimensions = pd.DataFrame([get_mbti_dimensions(pred) for pred in test_predictions], columns=['I/E', 'N/S', 'F/T', 'J/P'])\n",
        "    test_accuracy = accuracy_score(test_df[dimension], test_pred_dimensions[dimension])\n",
        "    test_precision = precision_score(test_df[dimension], test_pred_dimensions[dimension])\n",
        "    test_recall = recall_score(test_df[dimension], test_pred_dimensions[dimension])\n",
        "    test_f1 = f1_score(test_df[dimension], test_pred_dimensions[dimension])\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Train Accuracy for {dimension}: {train_accuracy}\")\n",
        "    print(f\"Test Accuracy for {dimension}: {test_accuracy}\")\n",
        "    print(f\"Average Accuracy for {dimension}: {(train_accuracy + test_accuracy) / 2}\\n\")\n",
        "    print(f\"Train Precision for {dimension}: {train_precision}\")\n",
        "    print(f\"Test Precision for {dimension}: {test_precision}\")\n",
        "    print(f\"Train Recall for {dimension}: {train_recall}\")\n",
        "    print(f\"Test Recall for {dimension}: {test_recall}\")\n",
        "    print(f\"Train F1 Score for {dimension}: {train_f1}\")\n",
        "    print(f\"Test F1 Score for {dimension}: {test_f1}\\n\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "v05JjkuySeZC",
        "RAvuONewUBIr",
        "anwvM-SiJou1"
      ],
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}